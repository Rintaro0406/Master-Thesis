{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8514456-0f2f-47f9-895f-73d047c1b705",
   "metadata": {},
   "source": [
    "# Introduction to CNN (Convolutional Neural Networks)\n",
    "#### \n",
    "#### Aim: Understanding Convolutional Neural Networks\n",
    "#### This introduction implements the example code from 'Deep Learning with Python' (2022, Francois Chollet).\n",
    "#### Multiclass  classification using MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58b3c4a1-e5f9-4abe-a920-e2c9209392ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43095ac-2aa7-4bd3-b1f2-87b2cbe08238",
   "metadata": {},
   "source": [
    "### 1. Instanisation of CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d05697c-d130-4dd0-94f2-7d6f02b7afa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs  = keras.Input(shape=(28, 28, 1)) # 28*28 pixel and 1 channel like MNIST image\n",
    "x       = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs) #output size is 32, window is 3*3 matrix\n",
    "x       = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x       = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x       = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x       = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x       = layers.Flatten()(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model   = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c64e65-a650-4b9f-a3b7-eb365ee1729d",
   "metadata": {},
   "source": [
    "### 2. showing the achitecture of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3093b882-5677-4858-9bc2-9f1bc9eef47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1152)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                11530     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 104,202\n",
      "Trainable params: 104,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3248e7b2-1565-403c-94ca-16e491192f6e",
   "metadata": {},
   "source": [
    "#### Due to boundary effects, the output size reduces from 28 to 26.\n",
    "#### If you wish to maintain the output dimension of the convolutional layer the same as the input layer, you will need to use padding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d313c6bb-78f1-44df-b302-3e7c0d9f23b1",
   "metadata": {},
   "source": [
    "### 3. Train the CNN with using MNIST images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ea4314f-e0df-41b5-8113-117b8a0e42bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype(\"float32\")/255\n",
    "test_images  = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images  = test_images.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "146bb004-a501-4071-b000-db653f1efc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 8s 4ms/step - loss: 0.1504 - accuracy: 0.9540\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0440 - accuracy: 0.9863\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0298 - accuracy: 0.9908\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 3s 4ms/step - loss: 0.0231 - accuracy: 0.9929\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.0179 - accuracy: 0.9945\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd2a5f5bca0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=\"rmsprop\",\n",
    "             loss=\"sparse_categorical_crossentropy\",  ## since classification, therefore crossentropy\n",
    "             metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)  ## training loop use 64 mini batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0706bd2-1d5d-4ee3-b209-2b1aa7b06dd8",
   "metadata": {},
   "source": [
    "### 4. Evaluate the model using test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04f57f27-4f17-48ac-8f99-a5fba2d2a6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0230 - accuracy: 0.9929\n",
      "Test accuracy: 0.993\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0518da06-84f1-478f-ba32-382107bc45c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
